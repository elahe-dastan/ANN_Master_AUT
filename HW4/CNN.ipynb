{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torchvision import models, transforms, datasets\n",
    "from torchvision.io import read_image\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from shutil import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOOD_PATH = \"./dataset/food-101\"\n",
    "IMG_PATH = FOOD_PATH+\"/images\"\n",
    "META_PATH = FOOD_PATH+\"/meta\"\n",
    "TRAIN_PATH = FOOD_PATH+\"/train\"\n",
    "VALID_PATH = FOOD_PATH+\"/valid\"\n",
    "MODEL_PATH = 'model_data/'\n",
    "IMAGENET_STATS = [(0.485, 0.456, 0.406), (0.229, 0.224, 0.225)]\n",
    "BATCH_SIZE = 500\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making dataloaders for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FOOD101():\n",
    "    def __init__(self):\n",
    "        self.train_ds, self.valid_ds, self.train_cls, self.valid_cls = [None]*4\n",
    "        self.imgenet_mean = IMAGENET_STATS[0]\n",
    "        self.imgenet_std = IMAGENET_STATS[1]\n",
    "        \n",
    "    def _get_tfms(self):\n",
    "        train_tfms = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(self.imgenet_mean, self.imgenet_std)])\n",
    "        \n",
    "        valid_tfms = transforms.Compose([\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(self.imgenet_mean, self.imgenet_std)])        \n",
    "        return train_tfms, valid_tfms            \n",
    "            \n",
    "    def get_dataset(self,root_dir='dataset/food-101/'):\n",
    "        train_tfms, valid_tfms = self._get_tfms() # transformations\n",
    "        self.train_ds = datasets.ImageFolder(root=TRAIN_PATH, transform=train_tfms)\n",
    "        self.valid_ds = datasets.ImageFolder(root=VALID_PATH, transform=valid_tfms)        \n",
    "        self.train_classes = self.train_ds.classes\n",
    "        self.valid_classes = self.valid_ds.classes\n",
    "\n",
    "        assert self.train_classes==self.valid_classes\n",
    "        return self.train_ds, self.valid_ds, self.train_classes\n",
    "\n",
    "    \n",
    "    def get_dls(self, train_ds, valid_ds, bs, **kwargs):\n",
    "        return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "               DataLoader(valid_ds, batch_size=bs//2, shuffle=False, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = FOOD101() \n",
    "train_ds, valid_ds, classes = food.get_dataset()\n",
    "dls = food.get_dls(train_ds, valid_ds, BATCH_SIZE)\n",
    "train_dl, valid_dl = dls[0], dls[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    layers = []\n",
    "\n",
    "    # in_channels, out_channels, kernel_size\n",
    "    layers.append(nn.Conv2d(3, 5, 8))\n",
    "    layers.append(nn.MaxPool2d(3, stride=1))\n",
    "\n",
    "    layers.append(nn.Conv2d(5, 5, 8))\n",
    "    layers.append(nn.MaxPool2d(8, stride=1))\n",
    "\n",
    "    layers.append(nn.Conv2d(5, 5, 8))\n",
    "    layers.append(nn.MaxPool2d(8, stride=1))\n",
    "    \n",
    "    layers.append(nn.Conv2d(5, 5, 8))\n",
    "    layers.append(nn.MaxPool2d(8, stride=1))\n",
    "    \n",
    "    layers.append(nn.Conv2d(5, 5, 8))\n",
    "    layers.append(nn.MaxPool2d(3))\n",
    "    \n",
    "    layers.append(nn.Conv2d(5, 5, 8))\n",
    "    layers.append(nn.MaxPool2d(8))\n",
    "    \n",
    "    layers.append(nn.Flatten())\n",
    "\n",
    "    layers.append(nn.Linear(180, 130))\n",
    "    layers.append(nn.ReLU())\n",
    "\n",
    "    layers.append(nn.Linear(130, 101))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.Softmax())\n",
    "    \n",
    "    model = nn.Sequential(*layers)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X.to(device))\n",
    "        loss = loss_fn(pred, y.to(device))\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X.to(device))\n",
    "            test_loss += loss_fn(pred, y.to(device)).item()\n",
    "            correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, test_dataloader, learning_rate = 0.9):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "    for t in range(EPOCHS):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_loop(test_dataloader, model, loss_fn)\n",
    "        scheduler.step()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9ad863feac43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    393\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 395\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    396\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "model = build_model().to(device)\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raha/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4.615132  [    0/75750]\n",
      "loss: 4.615136  [ 5000/75750]\n",
      "loss: 4.615087  [10000/75750]\n",
      "loss: 4.615105  [15000/75750]\n",
      "loss: 4.615108  [20000/75750]\n",
      "loss: 4.615122  [25000/75750]\n",
      "loss: 4.615108  [30000/75750]\n",
      "loss: 4.615126  [35000/75750]\n",
      "loss: 4.615112  [40000/75750]\n",
      "loss: 4.615110  [45000/75750]\n",
      "loss: 4.615125  [50000/75750]\n",
      "loss: 4.615018  [55000/75750]\n",
      "loss: 4.613444  [60000/75750]\n",
      "loss: 4.615230  [65000/75750]\n",
      "loss: 4.615106  [70000/75750]\n",
      "loss: 4.615120  [75000/75750]\n",
      "Test Error: \n",
      " Accuracy: 0.8%, Avg loss: 4.615118 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.615114  [    0/75750]\n",
      "loss: 4.615113  [ 5000/75750]\n",
      "loss: 4.615103  [10000/75750]\n",
      "loss: 4.615142  [15000/75750]\n",
      "loss: 4.614994  [20000/75750]\n",
      "loss: 4.615280  [25000/75750]\n",
      "loss: 4.615345  [30000/75750]\n",
      "loss: 4.615007  [35000/75750]\n",
      "loss: 4.619780  [40000/75750]\n",
      "loss: 4.627625  [45000/75750]\n",
      "loss: 4.625986  [50000/75750]\n",
      "loss: 4.619992  [55000/75750]\n",
      "loss: 4.621992  [60000/75750]\n",
      "loss: 4.625992  [65000/75750]\n",
      "loss: 4.615992  [70000/75750]\n",
      "loss: 4.617992  [75000/75750]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.622137 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 4.619992  [    0/75750]\n",
      "loss: 4.621992  [ 5000/75750]\n",
      "loss: 4.619992  [10000/75750]\n",
      "loss: 4.615992  [15000/75750]\n",
      "loss: 4.629992  [20000/75750]\n",
      "loss: 4.613992  [25000/75750]\n",
      "loss: 4.621992  [30000/75750]\n",
      "loss: 4.623992  [35000/75750]\n",
      "loss: 4.619992  [40000/75750]\n",
      "loss: 4.625992  [45000/75750]\n",
      "loss: 4.623992  [50000/75750]\n",
      "loss: 4.619992  [55000/75750]\n",
      "loss: 4.625992  [60000/75750]\n",
      "loss: 4.619992  [65000/75750]\n",
      "loss: 4.619992  [70000/75750]\n",
      "loss: 4.623992  [75000/75750]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.622098 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4.627992  [    0/75750]\n",
      "loss: 4.621992  [ 5000/75750]\n",
      "loss: 4.625992  [10000/75750]\n",
      "loss: 4.621992  [15000/75750]\n",
      "loss: 4.619992  [20000/75750]\n",
      "loss: 4.613992  [25000/75750]\n",
      "loss: 4.619992  [30000/75750]\n",
      "loss: 4.625992  [35000/75750]\n",
      "loss: 4.619992  [40000/75750]\n",
      "loss: 4.619992  [45000/75750]\n",
      "loss: 4.615992  [50000/75750]\n",
      "loss: 4.619992  [55000/75750]\n",
      "loss: 4.617992  [60000/75750]\n",
      "loss: 4.623992  [65000/75750]\n",
      "loss: 4.617992  [70000/75750]\n",
      "loss: 4.623992  [75000/75750]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.622098 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 4.625992  [    0/75750]\n",
      "loss: 4.623992  [ 5000/75750]\n",
      "loss: 4.621992  [10000/75750]\n",
      "loss: 4.617992  [15000/75750]\n",
      "loss: 4.623992  [20000/75750]\n",
      "loss: 4.623992  [25000/75750]\n",
      "loss: 4.623992  [30000/75750]\n",
      "loss: 4.623992  [35000/75750]\n",
      "loss: 4.623992  [40000/75750]\n",
      "loss: 4.619992  [45000/75750]\n",
      "loss: 4.623992  [50000/75750]\n",
      "loss: 4.617992  [55000/75750]\n",
      "loss: 4.623992  [60000/75750]\n",
      "loss: 4.621992  [65000/75750]\n",
      "loss: 4.619992  [70000/75750]\n",
      "loss: 4.621992  [75000/75750]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.622098 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
